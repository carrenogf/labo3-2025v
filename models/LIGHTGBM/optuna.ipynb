{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2923946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f933b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/dt_fe2.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "402287a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['product_id', 'customer_id', 'periodo', 'plan_precios_cuidados',\n",
       "       'cust_request_qty', 'cust_request_tn', 'tn', 'cat1', 'cat2', 'cat3',\n",
       "       'brand', 'sku_size', 'stock_final', 'periodo_dt', 'target', 'month',\n",
       "       'year', 'quarter', 'semester', 'is_month_end', 'season',\n",
       "       'size_vs_category', 'lag_1m', 'lag_2m', 'lag_3m', 'rolling_3m_mean',\n",
       "       'annual_trend', 'seasonal_variation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10880260",
   "metadata": {},
   "source": [
    "# Pruebas sin CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d60bf35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 19:03:47,655] A new study created in RDB with name: lightgbm_sin_cv\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 19:04:50,026] Trial 0 finished with value: 0.045658001287507084 and parameters: {'num_leaves': 105, 'learning_rate': 0.024315929579374472, 'feature_fraction': 0.7888657299143276, 'bagging_fraction': 0.4745455361773574, 'bagging_freq': 4, 'min_child_samples': 83, 'lambda_l1': 0.001559820251810067, 'lambda_l2': 0.6653187540435737, 'max_depth': 8}. Best is trial 0 with value: 0.045658001287507084.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 19:05:06,729] Trial 1 finished with value: 0.04869099846492722 and parameters: {'num_leaves': 251, 'learning_rate': 0.08384975193198724, 'feature_fraction': 0.6185285582491427, 'bagging_fraction': 0.5367390396767875, 'bagging_freq': 3, 'min_child_samples': 20, 'lambda_l1': 0.6557882888668388, 'lambda_l2': 0.049556939238187936, 'max_depth': 3}. Best is trial 0 with value: 0.045658001287507084.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 19:09:07,679] Trial 2 finished with value: 0.048768083748518584 and parameters: {'num_leaves': 41, 'learning_rate': 0.0012953939100278315, 'feature_fraction': 0.4947528571211099, 'bagging_fraction': 0.8496448269936433, 'bagging_freq': 3, 'min_child_samples': 37, 'lambda_l1': 1.0368596714280491, 'lambda_l2': 7.994094023377977e-05, 'max_depth': 5}. Best is trial 0 with value: 0.045658001287507084.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 19:09:55,136] Trial 3 finished with value: 0.049830385309107196 and parameters: {'num_leaves': 83, 'learning_rate': 0.014668423077996333, 'feature_fraction': 0.4572346675532605, 'bagging_fraction': 0.861846828349236, 'bagging_freq': 2, 'min_child_samples': 12, 'lambda_l1': 2.8062736197912525e-07, 'lambda_l2': 8.325322896669433e-05, 'max_depth': 4}. Best is trial 0 with value: 0.045658001287507084.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 19:11:07,480] Trial 4 finished with value: 0.04802406784747196 and parameters: {'num_leaves': 200, 'learning_rate': 0.008034961838680212, 'feature_fraction': 0.7288556302064395, 'bagging_fraction': 0.7345340881759195, 'bagging_freq': 1, 'min_child_samples': 10, 'lambda_l1': 2.0856614942602683e-05, 'lambda_l2': 0.16423736813617806, 'max_depth': 12}. Best is trial 0 with value: 0.045658001287507084.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 19:14:20,888] Trial 5 finished with value: 0.04489488208998924 and parameters: {'num_leaves': 279, 'learning_rate': 0.008673572986315565, 'feature_fraction': 0.5209550691724845, 'bagging_fraction': 0.933307240397997, 'bagging_freq': 7, 'min_child_samples': 38, 'lambda_l1': 5.038483781578341e-07, 'lambda_l2': 3.663934803235366e-08, 'max_depth': 8}. Best is trial 5 with value: 0.04489488208998924.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 19:14:49,459] Trial 6 finished with value: 0.04562807398460649 and parameters: {'num_leaves': 119, 'learning_rate': 0.06721222935362887, 'feature_fraction': 0.7100097740701599, 'bagging_fraction': 0.4050073964511204, 'bagging_freq': 7, 'min_child_samples': 79, 'lambda_l1': 0.12030635067456703, 'lambda_l2': 4.9608960638579665e-06, 'max_depth': 8}. Best is trial 5 with value: 0.04489488208998924.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 19:16:52,721] Trial 7 finished with value: 0.04363257681328295 and parameters: {'num_leaves': 272, 'learning_rate': 0.015423249848438758, 'feature_fraction': 0.6186135142670658, 'bagging_fraction': 0.6858656542404591, 'bagging_freq': 4, 'min_child_samples': 94, 'lambda_l1': 3.162117683378878, 'lambda_l2': 2.8531953297372876, 'max_depth': 11}. Best is trial 7 with value: 0.04363257681328295.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 19:18:21,603] Trial 8 finished with value: 0.04792519270218773 and parameters: {'num_leaves': 165, 'learning_rate': 0.00465025057292379, 'feature_fraction': 0.6356571844321588, 'bagging_fraction': 0.46282904109642414, 'bagging_freq': 6, 'min_child_samples': 86, 'lambda_l1': 0.0003099586270219808, 'lambda_l2': 1.6407241315352155e-05, 'max_depth': 4}. Best is trial 7 with value: 0.04363257681328295.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 19:19:49,503] Trial 9 finished with value: 0.04606532555269521 and parameters: {'num_leaves': 208, 'learning_rate': 0.017455751783358148, 'feature_fraction': 0.4686348742376241, 'bagging_fraction': 0.6276559699549187, 'bagging_freq': 4, 'min_child_samples': 50, 'lambda_l1': 4.851549341221651e-05, 'lambda_l2': 3.968726741019542e-07, 'max_depth': 10}. Best is trial 7 with value: 0.04363257681328295.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 19:27:50,454] Trial 10 finished with value: 0.04683888472483588 and parameters: {'num_leaves': 290, 'learning_rate': 0.0019402988527601817, 'feature_fraction': 0.9561444153318791, 'bagging_fraction': 0.7079133685391124, 'bagging_freq': 5, 'min_child_samples': 97, 'lambda_l1': 8.40272975379985, 'lambda_l2': 0.006776409387310367, 'max_depth': 12}. Best is trial 7 with value: 0.04363257681328295.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 19:35:46,593] Trial 11 finished with value: 0.04372465576891174 and parameters: {'num_leaves': 296, 'learning_rate': 0.004598371307128175, 'feature_fraction': 0.5929146653551124, 'bagging_fraction': 0.9738656803219204, 'bagging_freq': 7, 'min_child_samples': 66, 'lambda_l1': 1.6218909935420052e-07, 'lambda_l2': 1.2092545300999241e-08, 'max_depth': 10}. Best is trial 7 with value: 0.04363257681328295.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 19:44:00,314] Trial 12 finished with value: 0.04458117926129269 and parameters: {'num_leaves': 241, 'learning_rate': 0.0032783699834340483, 'feature_fraction': 0.5904234196360353, 'bagging_fraction': 0.9926026069490513, 'bagging_freq': 5, 'min_child_samples': 64, 'lambda_l1': 0.015677489524727632, 'lambda_l2': 5.707538743907529, 'max_depth': 10}. Best is trial 7 with value: 0.04363257681328295.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 19:45:06,031] Trial 13 finished with value: 0.045423917763594314 and parameters: {'num_leaves': 293, 'learning_rate': 0.035663664787491445, 'feature_fraction': 0.844199294255672, 'bagging_fraction': 0.8046657025413557, 'bagging_freq': 5, 'min_child_samples': 64, 'lambda_l1': 2.6751499775624294e-08, 'lambda_l2': 0.012254281357562223, 'max_depth': 10}. Best is trial 7 with value: 0.04363257681328295.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 19:51:18,649] Trial 14 finished with value: 0.04338014011658282 and parameters: {'num_leaves': 232, 'learning_rate': 0.004648054506981842, 'feature_fraction': 0.5703341269914189, 'bagging_fraction': 0.5990528265244626, 'bagging_freq': 6, 'min_child_samples': 100, 'lambda_l1': 3.392866762405977e-06, 'lambda_l2': 0.0011444820553097982, 'max_depth': 11}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 19:52:49,210] Trial 15 finished with value: 0.04403145633186203 and parameters: {'num_leaves': 216, 'learning_rate': 0.03727366847670293, 'feature_fraction': 0.557865862844801, 'bagging_fraction': 0.6108635577829442, 'bagging_freq': 6, 'min_child_samples': 96, 'lambda_l1': 4.407060837894872e-06, 'lambda_l2': 0.002047792367311771, 'max_depth': 12}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 19:56:35,270] Trial 16 finished with value: 0.04786845103737907 and parameters: {'num_leaves': 168, 'learning_rate': 0.002601836078647273, 'feature_fraction': 0.4088762637846404, 'bagging_fraction': 0.62129438076275, 'bagging_freq': 3, 'min_child_samples': 76, 'lambda_l1': 0.005335530590767515, 'lambda_l2': 6.74426558128862, 'max_depth': 6}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 19:59:54,113] Trial 17 finished with value: 0.043908696457107856 and parameters: {'num_leaves': 234, 'learning_rate': 0.0063347981825505485, 'feature_fraction': 0.7960758973758602, 'bagging_fraction': 0.5495712566635004, 'bagging_freq': 6, 'min_child_samples': 97, 'lambda_l1': 3.609598332740006e-06, 'lambda_l2': 0.001030409110395995, 'max_depth': 11}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 20:05:36,217] Trial 18 finished with value: 0.04845912128553586 and parameters: {'num_leaves': 258, 'learning_rate': 0.001018486782448643, 'feature_fraction': 0.665147219679469, 'bagging_fraction': 0.7580244399767946, 'bagging_freq': 4, 'min_child_samples': 89, 'lambda_l1': 0.0001293607997384593, 'lambda_l2': 0.4661463171423866, 'max_depth': 9}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 20:07:09,193] Trial 19 finished with value: 0.0469809705078075 and parameters: {'num_leaves': 188, 'learning_rate': 0.013181472535207706, 'feature_fraction': 0.9459763525564924, 'bagging_fraction': 0.6731138360874043, 'bagging_freq': 2, 'min_child_samples': 72, 'lambda_l1': 0.04462805870896763, 'lambda_l2': 0.0003613664627300378, 'max_depth': 7}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 20:08:17,270] Trial 20 finished with value: 0.0448273862310064 and parameters: {'num_leaves': 266, 'learning_rate': 0.022468302126266944, 'feature_fraction': 0.6732268590438839, 'bagging_fraction': 0.5650766163026761, 'bagging_freq': 5, 'min_child_samples': 55, 'lambda_l1': 0.001574420087925732, 'lambda_l2': 1.036276712356498e-06, 'max_depth': 11}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 20:14:41,124] Trial 21 finished with value: 0.04355969746767964 and parameters: {'num_leaves': 300, 'learning_rate': 0.004680202435033594, 'feature_fraction': 0.5464268892235702, 'bagging_fraction': 0.7833252243944941, 'bagging_freq': 7, 'min_child_samples': 91, 'lambda_l1': 2.6132883204569325e-08, 'lambda_l2': 1.1941156842801066e-08, 'max_depth': 11}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 20:20:34,683] Trial 22 finished with value: 0.043563461926359806 and parameters: {'num_leaves': 236, 'learning_rate': 0.0053644765610950254, 'feature_fraction': 0.5351200769518062, 'bagging_fraction': 0.6672979107793475, 'bagging_freq': 6, 'min_child_samples': 100, 'lambda_l1': 1.0541476265049852e-08, 'lambda_l2': 2.7363174864585927e-07, 'max_depth': 11}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 20:25:48,572] Trial 23 finished with value: 0.04424571921867283 and parameters: {'num_leaves': 227, 'learning_rate': 0.004881480209970671, 'feature_fraction': 0.5493254142052414, 'bagging_fraction': 0.7655166712407114, 'bagging_freq': 6, 'min_child_samples': 89, 'lambda_l1': 1.3426697001973321e-08, 'lambda_l2': 2.1370150450709088e-07, 'max_depth': 9}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 20:30:42,638] Trial 24 finished with value: 0.045780071217650264 and parameters: {'num_leaves': 134, 'learning_rate': 0.0028943643690507795, 'feature_fraction': 0.4227950007440386, 'bagging_fraction': 0.6557322741670719, 'bagging_freq': 7, 'min_child_samples': 100, 'lambda_l1': 5.471412460041455e-08, 'lambda_l2': 3.667462963412335e-08, 'max_depth': 11}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 20:36:55,878] Trial 25 finished with value: 0.04610370392374813 and parameters: {'num_leaves': 184, 'learning_rate': 0.0019686404517345927, 'feature_fraction': 0.5283745885130348, 'bagging_fraction': 0.8102507795457584, 'bagging_freq': 6, 'min_child_samples': 88, 'lambda_l1': 1.5714697988268291e-06, 'lambda_l2': 3.415169600289538e-06, 'max_depth': 9}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 20:39:48,037] Trial 26 finished with value: 0.04472904800807798 and parameters: {'num_leaves': 256, 'learning_rate': 0.006518790241701197, 'feature_fraction': 0.48937297221758036, 'bagging_fraction': 0.8955171167818481, 'bagging_freq': 7, 'min_child_samples': 100, 'lambda_l1': 1.0061234199792957e-08, 'lambda_l2': 2.4003919136735067e-07, 'max_depth': 12}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 20:46:24,134] Trial 27 finished with value: 0.04375576725084492 and parameters: {'num_leaves': 223, 'learning_rate': 0.003660474482381542, 'feature_fraction': 0.5615567657386711, 'bagging_fraction': 0.590057312328615, 'bagging_freq': 6, 'min_child_samples': 81, 'lambda_l1': 9.429939233559622e-08, 'lambda_l2': 1.3174061509983392e-08, 'max_depth': 11}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 20:50:09,671] Trial 28 finished with value: 0.0469040006955052 and parameters: {'num_leaves': 146, 'learning_rate': 0.002113490761444755, 'feature_fraction': 0.44775262688121503, 'bagging_fraction': 0.5021615124634031, 'bagging_freq': 7, 'min_child_samples': 71, 'lambda_l1': 1.359501243594216e-06, 'lambda_l2': 2.7028193131489533e-05, 'max_depth': 7}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 20:51:41,749] Trial 29 finished with value: 0.04667886697897097 and parameters: {'num_leaves': 87, 'learning_rate': 0.0112157050396232, 'feature_fraction': 0.7346762201459153, 'bagging_fraction': 0.7832327832810694, 'bagging_freq': 5, 'min_child_samples': 84, 'lambda_l1': 1.4664524842982311e-05, 'lambda_l2': 5.211614924985176e-08, 'max_depth': 9}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 20:55:48,056] Trial 30 finished with value: 0.04424043815063176 and parameters: {'num_leaves': 192, 'learning_rate': 0.005881005701683001, 'feature_fraction': 0.5104297268889578, 'bagging_fraction': 0.7137548050012535, 'bagging_freq': 6, 'min_child_samples': 92, 'lambda_l1': 5.351411951282792e-07, 'lambda_l2': 2.3846723109095333e-06, 'max_depth': 10}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 20:58:26,465] Trial 31 finished with value: 0.04380012456793522 and parameters: {'num_leaves': 277, 'learning_rate': 0.009849344816880566, 'feature_fraction': 0.6071028311947235, 'bagging_fraction': 0.6707423655894621, 'bagging_freq': 4, 'min_child_samples': 92, 'lambda_l1': 6.525601129047846e-08, 'lambda_l2': 0.04103287346758015, 'max_depth': 11}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 21:00:01,119] Trial 32 finished with value: 0.04424182870031909 and parameters: {'num_leaves': 271, 'learning_rate': 0.01911033082168525, 'feature_fraction': 0.6438144861778674, 'bagging_fraction': 0.677958890989693, 'bagging_freq': 4, 'min_child_samples': 94, 'lambda_l1': 6.801394698934543, 'lambda_l2': 1.2824864465109544, 'max_depth': 11}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 21:01:04,568] Trial 33 finished with value: 0.04423289144121952 and parameters: {'num_leaves': 255, 'learning_rate': 0.028412920987379308, 'feature_fraction': 0.5776982609966769, 'bagging_fraction': 0.7243024979932065, 'bagging_freq': 3, 'min_child_samples': 83, 'lambda_l1': 0.0010795802234975164, 'lambda_l2': 0.000167524825872368, 'max_depth': 12}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 21:06:09,824] Trial 34 finished with value: 0.04479884393168038 and parameters: {'num_leaves': 245, 'learning_rate': 0.003821635089240883, 'feature_fraction': 0.6270094923630378, 'bagging_fraction': 0.5182229852548098, 'bagging_freq': 5, 'min_child_samples': 32, 'lambda_l1': 0.7639698309441546, 'lambda_l2': 6.884196936897345e-08, 'max_depth': 10}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 21:07:44,400] Trial 35 finished with value: 0.04732981191509581 and parameters: {'num_leaves': 41, 'learning_rate': 0.0076351081887026185, 'feature_fraction': 0.6763780533352501, 'bagging_fraction': 0.8443724422430173, 'bagging_freq': 7, 'min_child_samples': 100, 'lambda_l1': 3.333011798444898e-08, 'lambda_l2': 0.16750482981802872, 'max_depth': 12}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 21:10:07,656] Trial 36 finished with value: 0.044121789649979516 and parameters: {'num_leaves': 281, 'learning_rate': 0.012904231018215896, 'feature_fraction': 0.5321276319194501, 'bagging_fraction': 0.6467604267030931, 'bagging_freq': 2, 'min_child_samples': 76, 'lambda_l1': 2.559037349459051e-07, 'lambda_l2': 1.3812316264288444e-05, 'max_depth': 11}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 21:12:05,531] Trial 37 finished with value: 0.046272373934718565 and parameters: {'num_leaves': 237, 'learning_rate': 0.009532322702498083, 'feature_fraction': 0.759207319526969, 'bagging_fraction': 0.5854005979002374, 'bagging_freq': 3, 'min_child_samples': 18, 'lambda_l1': 1.3844311861177509e-05, 'lambda_l2': 8.439899758268078e-07, 'max_depth': 9}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 21:13:07,397] Trial 38 finished with value: 0.04519252304239748 and parameters: {'num_leaves': 270, 'learning_rate': 0.06088240744166738, 'feature_fraction': 0.4836165492129716, 'bagging_fraction': 0.7472744182401225, 'bagging_freq': 4, 'min_child_samples': 92, 'lambda_l1': 0.3118329125166773, 'lambda_l2': 0.03577025655354802, 'max_depth': 12}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 21:14:55,864] Trial 39 finished with value: 0.0499269591290243 and parameters: {'num_leaves': 299, 'learning_rate': 0.0015682290369027265, 'feature_fraction': 0.4439746373905566, 'bagging_fraction': 0.4653854220111303, 'bagging_freq': 6, 'min_child_samples': 56, 'lambda_l1': 6.47160883253532e-07, 'lambda_l2': 1.2966951519416958, 'max_depth': 3}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 21:18:10,507] Trial 40 finished with value: 0.045065624241474075 and parameters: {'num_leaves': 206, 'learning_rate': 0.00529343533405848, 'feature_fraction': 0.6149285818282805, 'bagging_fraction': 0.6983221040574327, 'bagging_freq': 7, 'min_child_samples': 86, 'lambda_l1': 6.395357191689553e-05, 'lambda_l2': 0.0029277369529570334, 'max_depth': 8}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 21:22:13,346] Trial 41 finished with value: 0.04433576240750119 and parameters: {'num_leaves': 298, 'learning_rate': 0.0076600387190507045, 'feature_fraction': 0.5809873253429397, 'bagging_fraction': 0.9975810570929079, 'bagging_freq': 7, 'min_child_samples': 45, 'lambda_l1': 1.7282319660606418e-07, 'lambda_l2': 1.0331407345483758e-08, 'max_depth': 10}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 21:24:23,228] Trial 42 finished with value: 0.048362316694372826 and parameters: {'num_leaves': 281, 'learning_rate': 0.004310865333475764, 'feature_fraction': 0.596856087182541, 'bagging_fraction': 0.9411881252011401, 'bagging_freq': 7, 'min_child_samples': 5, 'lambda_l1': 1.4497490466331987e-07, 'lambda_l2': 1.209362451974542e-07, 'max_depth': 10}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 21:32:37,070] Trial 43 finished with value: 0.044563096946165254 and parameters: {'num_leaves': 285, 'learning_rate': 0.002517383495201897, 'feature_fraction': 0.5110665916489325, 'bagging_fraction': 0.8875472477088184, 'bagging_freq': 6, 'min_child_samples': 69, 'lambda_l1': 2.3162795127911757e-08, 'lambda_l2': 2.068610109261707e-08, 'max_depth': 11}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 21:38:15,894] Trial 44 finished with value: 0.04400333240635348 and parameters: {'num_leaves': 263, 'learning_rate': 0.004492575188286048, 'feature_fraction': 0.6513446514125397, 'bagging_fraction': 0.4301394794034156, 'bagging_freq': 7, 'min_child_samples': 61, 'lambda_l1': 2.4552423744374194, 'lambda_l2': 1.0457571301323522e-07, 'max_depth': 11}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 21:43:21,586] Trial 45 finished with value: 0.04403592979230686 and parameters: {'num_leaves': 248, 'learning_rate': 0.007044905309152943, 'feature_fraction': 0.544676250465997, 'bagging_fraction': 0.9525347150532607, 'bagging_freq': 5, 'min_child_samples': 76, 'lambda_l1': 4.020928456924506e-06, 'lambda_l2': 6.570516563403047e-07, 'max_depth': 10}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 21:45:32,743] Trial 46 finished with value: 0.043593924691019255 and parameters: {'num_leaves': 299, 'learning_rate': 0.015709724330054155, 'feature_fraction': 0.6994011903846877, 'bagging_fraction': 0.635923866005653, 'bagging_freq': 6, 'min_child_samples': 96, 'lambda_l1': 7.238401697078811e-08, 'lambda_l2': 2.5663685181426834e-08, 'max_depth': 12}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 21:47:13,548] Trial 47 finished with value: 0.04444904916009188 and parameters: {'num_leaves': 218, 'learning_rate': 0.014765545594133308, 'feature_fraction': 0.7155965127324063, 'bagging_fraction': 0.5964307325939132, 'bagging_freq': 6, 'min_child_samples': 96, 'lambda_l1': 1.080317554199756e-08, 'lambda_l2': 3.824291402739098e-05, 'max_depth': 12}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 21:48:33,854] Trial 48 finished with value: 0.04424105517869022 and parameters: {'num_leaves': 287, 'learning_rate': 0.017686539722422966, 'feature_fraction': 0.6876601917607138, 'bagging_fraction': 0.6282835965281385, 'bagging_freq': 1, 'min_child_samples': 80, 'lambda_l1': 4.8180732897060864e-08, 'lambda_l2': 9.911313780351666e-06, 'max_depth': 12}. Best is trial 14 with value: 0.04338014011658282.\n",
      "c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "[I 2025-05-29 21:49:54,434] Trial 49 finished with value: 0.045420118770955836 and parameters: {'num_leaves': 270, 'learning_rate': 0.027486871086114195, 'feature_fraction': 0.8305992465638163, 'bagging_fraction': 0.6889519859208475, 'bagging_freq': 5, 'min_child_samples': 90, 'lambda_l1': 1.36414437361265e-06, 'lambda_l2': 0.013571426534489056, 'max_depth': 12}. Best is trial 14 with value: 0.04338014011658282.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados:\n",
      "{'num_leaves': 232, 'learning_rate': 0.004648054506981842, 'feature_fraction': 0.5703341269914189, 'bagging_fraction': 0.5990528265244626, 'bagging_freq': 6, 'min_child_samples': 100, 'lambda_l1': 3.392866762405977e-06, 'lambda_l2': 0.0011444820553097982, 'max_depth': 11}\n",
      "Mejor RMSE: 0.0434\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import sqlite3\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "# === 1. Carga de datos y preprocesamiento ===\n",
    "# Asegurate de tener cargado tu DataFrame `df`\n",
    "\n",
    "df = df.drop(['periodo_dt', 'descripcion'], axis=1, errors='ignore')\n",
    "df_kgl = df[df[\"periodo\"] == 201912]\n",
    "df = df[~df[\"periodo\"].isin([201911, 201912])]\n",
    "\n",
    "# Codificar categóricas\n",
    "cat_cols = ['cat1', 'cat2', 'cat3', 'brand', 'plan_precios_cuidados']\n",
    "for col in cat_cols:\n",
    "    if col in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "# Separar features y target\n",
    "X = df.drop(columns=[\"target\"])\n",
    "y = df[\"target\"]\n",
    "\n",
    "# Split fijo para validación (sin CV)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# === 2. Definición del objetivo para Optuna ===\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"rmse\",\n",
    "        \"boosting_type\": \"gbdt\",\n",
    "        \"verbosity\": -1,\n",
    "        \"n_jobs\": -1,\n",
    "        \"seed\": 42,\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 300),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.001, 0.1, log=True),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_float(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"lambda_l1\": trial.suggest_float(\"lambda_l1\", 1e-8, 10.0, log=True),\n",
    "        \"lambda_l2\": trial.suggest_float(\"lambda_l2\", 1e-8, 10.0, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "    }\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        lgb.Dataset(X_train, label=y_train),\n",
    "        valid_sets=[lgb.Dataset(X_val, label=y_val)],\n",
    "        num_boost_round=1000,\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    "    )\n",
    "\n",
    "    preds = model.predict(X_val)\n",
    "    rmse = mean_squared_error(y_val, preds, squared=False)\n",
    "    return rmse\n",
    "\n",
    "# === 3. Configurar almacenamiento SQLite para Optuna ===\n",
    "os.makedirs(\"optuna_storage\", exist_ok=True)\n",
    "DB_PATH = \"optuna_storage/optuna_simple.db\"\n",
    "STUDY_NAME = \"lightgbm_sin_cv\"\n",
    "storage_url = f\"sqlite:///{DB_PATH}\"\n",
    "\n",
    "# === 4. Crear o cargar estudio ===\n",
    "study = optuna.create_study(\n",
    "    study_name=STUDY_NAME,\n",
    "    storage=storage_url,\n",
    "    direction=\"minimize\",\n",
    "    load_if_exists=True\n",
    ")\n",
    "\n",
    "# === 5. Ejecutar optimización ===\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# === 6. Mostrar resultados ===\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(study.best_params)\n",
    "print(f\"Mejor RMSE: {study.best_value:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6eedba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones para periodo 201912:\n",
      "[-4.87869999e+01 -5.75757666e+00  5.17383229e+00 ...  1.37966385e-03\n",
      "  2.17837551e-02  2.17837551e-02]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Entrenar con los mejores hiperparámetros\n",
    "best_params = study.best_params.copy()\n",
    "best_params.update({\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": \"rmse\",\n",
    "    \"verbosity\": -1,\n",
    "    \"n_jobs\": -1,\n",
    "    \"seed\": 42\n",
    "})\n",
    "\n",
    "# Entrenar una vez el modelo con esos parámetros (ej. sobre X_train si no querés usar todo)\n",
    "model = lgb.train(\n",
    "    best_params,\n",
    "    lgb.Dataset(X_train, label=y_train),\n",
    "    valid_sets=[lgb.Dataset(X_val, label=y_val)],\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    ")\n",
    "\n",
    "cat_cols = ['cat1', 'cat2', 'cat3', 'brand', 'plan_precios_cuidados']\n",
    "for col in cat_cols:\n",
    "    if col in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df_kgl[col] = le.fit_transform(df_kgl[col].astype(str))\n",
    "\n",
    "# Asegurar las mismas columnas\n",
    "X_kgl = df_kgl[X.columns]  # Misma estructura\n",
    "\n",
    "# === 9. Hacer predicción sobre nuevos datos ===\n",
    "preds_kgl = model.predict(X_kgl)\n",
    "\n",
    "# Mostrar o guardar resultados\n",
    "print(\"Predicciones para periodo 201912:\")\n",
    "print(preds_kgl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9e41664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "product_id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tn",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "01d63630-f218-45ec-a5ff-21926d942f5d",
       "rows": [
        [
         "0",
         "20001",
         "1262.1572397229875"
        ],
        [
         "1",
         "20002",
         "1059.6605926688273"
        ],
        [
         "2",
         "20003",
         "785.2578855548775"
        ],
        [
         "3",
         "20004",
         "647.1450973549987"
        ],
        [
         "4",
         "20005",
         "494.3701223399769"
        ],
        [
         "5",
         "20006",
         "388.1629185763083"
        ],
        [
         "6",
         "20007",
         "360.02339283969934"
        ],
        [
         "7",
         "20008",
         "307.1359050912836"
        ],
        [
         "8",
         "20009",
         "432.95101318258645"
        ],
        [
         "9",
         "20010",
         "688.9938733129701"
        ],
        [
         "10",
         "20011",
         "326.8982704082204"
        ],
        [
         "11",
         "20012",
         "261.0278535734104"
        ],
        [
         "12",
         "20013",
         "330.5196487230739"
        ],
        [
         "13",
         "20014",
         "360.1456829757395"
        ],
        [
         "14",
         "20015",
         "298.8836211449094"
        ],
        [
         "15",
         "20016",
         "277.48832454257416"
        ],
        [
         "16",
         "20017",
         "210.09893836934666"
        ],
        [
         "17",
         "20018",
         "211.560633883759"
        ],
        [
         "18",
         "20019",
         "343.4148820233913"
        ],
        [
         "19",
         "20020",
         "453.6019148223601"
        ],
        [
         "20",
         "20021",
         "377.00511627671455"
        ],
        [
         "21",
         "20022",
         "496.3187117532192"
        ],
        [
         "22",
         "20023",
         "240.90956304721362"
        ],
        [
         "23",
         "20024",
         "205.70469252293046"
        ],
        [
         "24",
         "20025",
         "156.69539602327583"
        ],
        [
         "25",
         "20026",
         "220.25945439432593"
        ],
        [
         "26",
         "20027",
         "197.49281572009352"
        ],
        [
         "27",
         "20028",
         "173.57499838972882"
        ],
        [
         "28",
         "20029",
         "135.3395426329871"
        ],
        [
         "29",
         "20030",
         "124.60831492991308"
        ],
        [
         "30",
         "20031",
         "157.84767435396714"
        ],
        [
         "31",
         "20032",
         "447.93830699842454"
        ],
        [
         "32",
         "20033",
         "156.28734324460837"
        ],
        [
         "33",
         "20035",
         "142.9633667980773"
        ],
        [
         "34",
         "20037",
         "181.70336939084362"
        ],
        [
         "35",
         "20038",
         "141.16189585557595"
        ],
        [
         "36",
         "20039",
         "137.0139973522448"
        ],
        [
         "37",
         "20041",
         "121.35555902594295"
        ],
        [
         "38",
         "20042",
         "135.80402627137775"
        ],
        [
         "39",
         "20043",
         "127.43718188390697"
        ],
        [
         "40",
         "20044",
         "136.42326141620808"
        ],
        [
         "41",
         "20045",
         "137.36061798504366"
        ],
        [
         "42",
         "20046",
         "140.50606854053356"
        ],
        [
         "43",
         "20047",
         "134.67063894472057"
        ],
        [
         "44",
         "20049",
         "150.6440467685691"
        ],
        [
         "45",
         "20050",
         "116.86359820393312"
        ],
        [
         "46",
         "20051",
         "111.99515093074163"
        ],
        [
         "47",
         "20052",
         "108.11002987236903"
        ],
        [
         "48",
         "20053",
         "136.55687370931312"
        ],
        [
         "49",
         "20054",
         "126.1722047351941"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 780
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>tn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20001</td>\n",
       "      <td>1262.157240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20002</td>\n",
       "      <td>1059.660593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20003</td>\n",
       "      <td>785.257886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20004</td>\n",
       "      <td>647.145097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20005</td>\n",
       "      <td>494.370122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>21263</td>\n",
       "      <td>0.404318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>21265</td>\n",
       "      <td>0.396308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>21266</td>\n",
       "      <td>0.394427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>21267</td>\n",
       "      <td>0.077200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>21276</td>\n",
       "      <td>0.079902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>780 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_id           tn\n",
       "0         20001  1262.157240\n",
       "1         20002  1059.660593\n",
       "2         20003   785.257886\n",
       "3         20004   647.145097\n",
       "4         20005   494.370122\n",
       "..          ...          ...\n",
       "775       21263     0.404318\n",
       "776       21265     0.396308\n",
       "777       21266     0.394427\n",
       "778       21267     0.077200\n",
       "779       21276     0.079902\n",
       "\n",
       "[780 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "productos_ok = pd.read_csv(\"https://storage.googleapis.com/open-courses/austral2025-af91/labo3v/product_id_apredecir201912.txt\", sep=\"\\t\")\n",
    "result = pd.DataFrame({\"product_id\": X_kgl[\"product_id\"], \"tn\": X_kgl[\"tn\"],  \"ypred\": preds_kgl})\n",
    "result[\"tn\"] = result[\"ypred\"] + result[\"tn\"]\n",
    "result = result[result[\"product_id\"].isin(productos_ok[\"product_id\"])]\n",
    "result = result.groupby(\"product_id\").agg({\"tn\":\"sum\"}).reset_index()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "715395f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"results/resultados_lgbm_1opt.csv\",sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13509664",
   "metadata": {},
   "source": [
    "# pruebas con CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "692e5526",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-29 18:47:47,354] A new study created in RDB with name: primera_optimizacion\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuevo estudio 'primera_optimizacion' creado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2025-05-29 18:53:45,446] Trial 0 failed with parameters: {'num_leaves': 125, 'learning_rate': 0.0180870615296578, 'feature_fraction': 0.7737019415710031, 'bagging_fraction': 0.9085842649015098, 'bagging_freq': 2, 'min_child_samples': 52, 'lambda_l1': 3.935282838035174e-05, 'lambda_l2': 4.275372907991264e-05, 'max_depth': 11} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\carre\\AppData\\Local\\Temp\\ipykernel_13592\\1664033529.py\", line 74, in objective\n",
      "    model = lgb.train(\n",
      "            ^^^^^^^^^^\n",
      "  File \"c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightgbm\\engine.py\", line 307, in train\n",
      "    booster.update(fobj=fobj)\n",
      "  File \"c:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightgbm\\basic.py\", line 4136, in update\n",
      "    _LIB.LGBM_BoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-05-29 18:53:45,484] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 134\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# 8. Ejecutar todo el proceso\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 134\u001b[0m     study \u001b[38;5;241m=\u001b[39m \u001b[43mrun_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;66;03m# Mostrar resultados\u001b[39;00m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMejores parámetros encontrados:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 128\u001b[0m, in \u001b[0;36mrun_optimization\u001b[1;34m()\u001b[0m\n\u001b[0;32m    125\u001b[0m optuna\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mset_verbosity(optuna\u001b[38;5;241m.\u001b[39mlogging\u001b[38;5;241m.\u001b[39mINFO)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;66;03m# Ejecutar optimización\u001b[39;00m\n\u001b[1;32m--> 128\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3600\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "File \u001b[1;32mc:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\study.py:451\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    350\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    357\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    358\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \n\u001b[0;32m    361\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 451\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:62\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:159\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 159\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:247\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    243\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    246\u001b[0m ):\n\u001b[1;32m--> 247\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[8], line 74\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     71\u001b[0m val_data \u001b[38;5;241m=\u001b[39m lgb\u001b[38;5;241m.\u001b[39mDataset(X_val, label\u001b[38;5;241m=\u001b[39my_val, reference\u001b[38;5;241m=\u001b[39mtrain_data)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# Entrenamiento\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\n\u001b[0;32m     80\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Predicción y evaluación\u001b[39;00m\n\u001b[0;32m     83\u001b[0m preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n",
      "File \u001b[1;32mc:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightgbm\\engine.py:307\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[0;32m    296\u001b[0m     cb(\n\u001b[0;32m    297\u001b[0m         callback\u001b[38;5;241m.\u001b[39mCallbackEnv(\n\u001b[0;32m    298\u001b[0m             model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    304\u001b[0m         )\n\u001b[0;32m    305\u001b[0m     )\n\u001b[1;32m--> 307\u001b[0m \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    309\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\carre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\lightgbm\\basic.py:4136\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   4133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[0;32m   4134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4135\u001b[0m _safe_call(\n\u001b[1;32m-> 4136\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4137\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4138\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4139\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4140\u001b[0m )\n\u001b[0;32m   4141\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[0;32m   4142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import sqlite3\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "\n",
    "# 1. Configuración de la base de datos SQLite para Optuna\n",
    "DB_NAME = \"optuna_studies.db\"\n",
    "STUDY_NAME = \"primera_optimizacion\"\n",
    "\n",
    "# Crear directorio si no existe\n",
    "os.makedirs(\"optuna_storage\", exist_ok=True)\n",
    "DB_PATH = f\"optuna_storage/{DB_NAME}\"\n",
    "\n",
    "# 2. Preparación de datos (asegúrate de haber hecho el feature engineering primero)\n",
    "# Eliminar variables no útiles para el modelo\n",
    "df = df.drop(['periodo_dt', 'descripcion'], axis=1, errors='ignore')\n",
    "\n",
    "df_kgl = df[df[\"periodo\"].isin([201912])]\n",
    "\n",
    "df = df.drop(df[df[\"periodo\"].isin([201911,201912])].index,axis=0)\n",
    "\n",
    "# Codificar variables categóricas\n",
    "cat_cols = ['cat1', 'cat2', 'cat3', 'brand', 'plan_precios_cuidados',]\n",
    "for col in cat_cols:\n",
    "    if col in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "# Separar features y target\n",
    "X = df.drop(['target'], axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# 3. Configuración de la validación cruzada temporal\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# 4. Función objetivo para Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbosity': -1,\n",
    "        'n_jobs': -1,\n",
    "        'seed': 42,\n",
    "        \n",
    "        # Parámetros a optimizar\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 300),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.1, log=True),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "    }\n",
    "    \n",
    "    # Validación cruzada\n",
    "    val_scores = []\n",
    "    for train_idx, val_idx in tscv.split(X):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        # Dataset de LightGBM\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(X_val, label=y_val, reference=train_data)\n",
    "        \n",
    "        # Entrenamiento\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets=[val_data],\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)],\n",
    "            num_boost_round=1000\n",
    "        )\n",
    "        \n",
    "        # Predicción y evaluación\n",
    "        preds = model.predict(X_val)\n",
    "        val_score = np.sqrt(mean_squared_error(y_val, preds))\n",
    "        val_scores.append(val_score)\n",
    "    \n",
    "    return np.mean(val_scores)\n",
    "\n",
    "# 5. Configuración del almacenamiento en SQLite\n",
    "def setup_optuna_storage():\n",
    "    # Crear conexión a la base de datos\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    conn.close()\n",
    "    \n",
    "    # URL de almacenamiento para Optuna\n",
    "    storage_url = f\"sqlite:///{DB_PATH}\"\n",
    "    return storage_url\n",
    "\n",
    "# 6. Función para cargar o crear estudio\n",
    "def get_or_create_study(storage_url, study_name):\n",
    "    try:\n",
    "        # Intentar cargar estudio existente\n",
    "        study = optuna.load_study(\n",
    "            study_name=study_name,\n",
    "            storage=storage_url\n",
    "        )\n",
    "        print(f\"Estudio '{study_name}' cargado con {len(study.trials)} trials existentes\")\n",
    "    except:\n",
    "        # Crear nuevo estudio si no existe\n",
    "        study = optuna.create_study(\n",
    "            study_name=study_name,\n",
    "            storage=storage_url,\n",
    "            direction=\"minimize\",\n",
    "            load_if_exists=True\n",
    "        )\n",
    "        print(f\"Nuevo estudio '{study_name}' creado\")\n",
    "    return study\n",
    "\n",
    "# 7. Ejecutar la optimización\n",
    "def run_optimization():\n",
    "    storage_url = setup_optuna_storage()\n",
    "    study = get_or_create_study(storage_url, STUDY_NAME)\n",
    "    \n",
    "    # Configurar logger para ver progreso\n",
    "    optuna.logging.set_verbosity(optuna.logging.INFO)\n",
    "    \n",
    "    # Ejecutar optimización\n",
    "    study.optimize(objective, n_trials=50, timeout=3600)\n",
    "    \n",
    "    return study\n",
    "\n",
    "# 8. Ejecutar todo el proceso\n",
    "if __name__ == \"__main__\":\n",
    "    study = run_optimization()\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    print(\"\\nMejores parámetros encontrados:\")\n",
    "    print(study.best_params)\n",
    "    print(f\"Mejor RMSE: {study.best_value:.4f}\")\n",
    "    \n",
    "    # 9. Entrenar modelo final con mejores parámetros\n",
    "    best_params = study.best_params\n",
    "    best_params.update({\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'verbosity': -1,\n",
    "        'seed': 42,\n",
    "        'n_jobs': -1\n",
    "    })\n",
    "    \n",
    "    final_model = lgb.LGBMRegressor(**best_params, n_estimators=1000)\n",
    "    final_model.fit(X, y)\n",
    "    \n",
    "    # 10. Guardar modelo final\n",
    "    import joblib\n",
    "    joblib.dump(final_model, 'lightgbm_optimized_model.pkl')\n",
    "    \n",
    "    # 11. Visualizaciones\n",
    "    print(\"\\nVisualizaciones disponibles:\")\n",
    "    print(f\"Base de datos de estudios: {DB_PATH}\")\n",
    "    \n",
    "    # Exportar resultados a DataFrame\n",
    "    trials_df = study.trials_dataframe()\n",
    "    trials_df.to_csv(\"optuna_storage/trials_results.csv\", index=False)\n",
    "    print(\"Resultados de trials guardados en optuna_storage/trials_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9374f44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
